{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nimport os\nimport numpy as np\n\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/Zhu_Rongji')\n\nimg_fld = ImageFolder('../input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled', transform=ToTensor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#so we have a discriminator and we have a generator\n#first we will create a discriminator - i will make it feedforward for now\n\nimg_size = (250 ** 2) * 3\nD = nn.Sequential(\n    nn.Linear(img_size, 256),\n    nn.LeakyReLU(0.2),\n    nn.Linear(256, 128),\n    nn.LeakyReLU(0.2),\n    nn.Linear(128, 1),\n    nn.Sigmoid()\n)\n\n#this is the generator model. It takes in a random input vector and then it \n\nG = nn.Sequential(\n    nn.Linear(64, 128),\n    nn.ReLU(),\n    nn.Linear(128, 128),\n    nn.ReLU(),\n    nn.Linear(128, img_size),\n    nn.Tanh()\n    \n)\n\n\nrandom_input_vector = torch.randn(2,64)\ndef mgraph(random_input_vector):\n    tst_out = (G(random_input_vector.to(torch.device(\"cuda\"))))\n    gg = tst_out.reshape(-1, 250, 250)\n    gg = gg.reshape(2,3,250, 250)\n    gg = gg[0].permute(1,2,0).cpu().detach()\n    import matplotlib.pyplot as plt\n    plt.imshow(gg)\n# mgraph(random_input_vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we will have a batch size of 33, because it is divisible by 13233\n#there is no validation set, becuase we are just generating things not actually like \nloss_fn = nn.BCELoss()\nd_opt = torch.optim.Adam(D.parameters(), lr = 2e-4)\ng_opt = torch.optim.Adam(G.parameters(), lr = 2e-4)\ndef reset_grad():\n    d_opt.zero_grad()\n    g_opt.zero_grad()\n    \ntrain_dl = DataLoader(img_fld, 33, shuffle=True)\n\nreal_labels = torch.ones(33,1).to(torch.device('cuda'))\nfake_labels = torch.zeros(33,1).to(torch.device('cuda'))\nprint(len(train_dl))\nloss_fn = nn.BCELoss()\nD = D.to(torch.device('cuda'))\nG = G.to(torch.device('cuda'))\ndef train_dis(xb):  \n    x = xb.view(xb.size(0), -1).to(torch.device('cuda'))\n\n    out = D(x)\n    d_loss_real = loss_fn(out, real_labels)\n    riv = torch.randn(33,64).to(torch.device('cuda'))\n    fake_images = G(riv)\n    outputs = D(fake_images)\n\n\n    d_loss_fake = loss_fn(outputs, fake_labels)\n    d_loss = d_loss_real + d_loss_fake\n    \n    reset_grad() #we need to reset the gradient before we calculate the loss so it doesnt append to the total gradient\n    d_loss.backward()\n    d_opt.step()\n    \n    \n\ndef train_gen():\n    z = torch.randn(33,64).to(torch.device('cuda'))\n    fake_images = G(z)\n    lbl = torch.ones(33,1).to(torch.device('cuda'))\n#     print(D(fake_images))\n    g_loss = loss_fn(D(fake_images), lbl)\n#     print(g_loss)\n    reset_grad()\n    g_loss.backward()\n    g_opt.step()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_opt = torch.optim.Adam(D.parameters(), lr = 2e-4)\ng_opt = torch.optim.Adam(G.parameters(), lr = 2e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_fn = nn.BCELoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #the discriminator kinda worked\n\n#training the discriminator is hella ezy\n# for images,_ in train_dl:\n    \n#     img = images.view(images.size(0), -1)\n#     train_dis(images.to(torch.device(\"cuda\")))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#you know actually, training on the gpu is soooo much faster, like a big difference rather than training on the cpu.\nfor xb, _ in train_dl:\n    x = xb.view(xb.size(0), -1).to(torch.device(\"cuda\"))\n    print(xb.size(0))\n    print(D(x))\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 2\n\nfor epoch in range(num_epochs):\n    for images,_ in train_dl:\n        train_dis(images.to(torch.device('cuda')))\n        train_gen()\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for xb, _ in train_dl:\n    xb = xb.view(xb.size(0), -1)\n    print(D(xb.to(torch.device('cuda'))))\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rand_inp_vector = torch.randn(1,64).to(torch.device('cuda'))\nprint(rand_inp_vector)\n\nsh = (G(rand_inp_vector.to(torch.device(\"cuda\"))))\n\nsh = sh.cpu().detach()\n\nsh = sh.reshape(-1, 250, 250)\n\nsh = sh.permute(1,2,0)\n\nplt.imshow(sh)\n\n\nprint(sh.shape)\n# gg = tst_out.reshape(-1, 250, 250)\n# gg = gg.reshape(2,3,250, 250)\n# gg = gg[0].permute(1,2,0).cpu().detach()\n# import matplotlib.pyplot as plt\n# plt.imshow(gg)\n\nimg = (img_fld[0][0]).permute(1,2,0)\n\n# plt.imshow(img)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
