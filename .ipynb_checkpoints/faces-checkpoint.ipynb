{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './26922_34595_bundle_archive/lfw-deepfunneled/lfw-deepfunneled'\n",
    "os.listdir('./26922_34595_bundle_archive/lfw-deepfunneled/lfw-deepfunneled')\n",
    "img_fld = ImageFolder(path, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we have a discriminator and we have a generator\n",
    "#first we will create a discriminator - i will make it feedforward for now\n",
    "\n",
    "img_size = (250 ** 2) * 3\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(img_size, 256),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(128, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "#this is the generator model. It takes in a random input vector and then it \n",
    "\n",
    "G = nn.Sequential(\n",
    "    nn.Linear(64, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, img_size),\n",
    "    nn.Tanh()\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "random_input_vector = torch.randn(2,64)\n",
    "def mgraph(random_input_vector):\n",
    "    tst_out = (G(random_input_vector.to(torch.device(\"cuda\"))))\n",
    "    gg = tst_out.reshape(-1, 250, 250)\n",
    "    gg = gg.reshape(2,3,250, 250)\n",
    "    gg = gg[0].permute(1,2,0).cpu().detach()\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(gg)\n",
    "# mgraph(random_input_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will have a batch size of 33, because it is divisible by 13233\n",
    "#there is no validation set, becuase we are just generating things not actually like \n",
    "loss_fn = nn.BCELoss()\n",
    "d_opt = torch.optim.Adam(D.parameters(), lr = 2e-4)\n",
    "g_opt = torch.optim.Adam(G.parameters(), lr = 2e-4)\n",
    "def reset_grad():\n",
    "    d_opt.zero_grad()\n",
    "    g_opt.zero_grad()\n",
    "    \n",
    "train_dl = DataLoader(img_fld, 33, shuffle=True)\n",
    "\n",
    "real_labels = torch.ones(33,1).to(torch.device('cuda'))\n",
    "fake_labels = torch.zeros(33,1).to(torch.device('cuda'))\n",
    "print(len(train_dl))\n",
    "loss_fn = nn.BCELoss()\n",
    "D = D.to(torch.device('cuda'))\n",
    "G = G.to(torch.device('cuda'))\n",
    "def train_dis(xb):  \n",
    "    x = xb.view(xb.size(0), -1).to(torch.device('cuda'))\n",
    "\n",
    "    out = D(x)\n",
    "    d_loss_real = loss_fn(out, real_labels)\n",
    "    riv = torch.randn(33,64).to(torch.device('cuda'))\n",
    "    fake_images = G(riv)\n",
    "    outputs = D(fake_images)\n",
    "\n",
    "\n",
    "    d_loss_fake = loss_fn(outputs, fake_labels)\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    reset_grad() #we need to reset the gradient before we calculate the loss so it doesnt append to the total gradient\n",
    "    d_loss.backward()\n",
    "    d_opt.step()\n",
    "    \n",
    "    \n",
    "\n",
    "def train_gen():\n",
    "    z = torch.randn(33,64).to(torch.device('cuda'))\n",
    "    fake_images = G(z)\n",
    "    lbl = torch.ones(33,1).to(torch.device('cuda'))\n",
    "#     print(D(fake_images))\n",
    "    g_loss = loss_fn(D(fake_images), lbl)\n",
    "#     print(g_loss)\n",
    "    reset_grad()\n",
    "    g_loss.backward()\n",
    "    g_opt.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_opt = torch.optim.Adam(D.parameters(), lr = 2e-4)\n",
    "g_opt = torch.optim.Adam(G.parameters(), lr = 2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #the discriminator kinda worked\n",
    "\n",
    "#training the discriminator is hella ezy\n",
    "# for images,_ in train_dl:\n",
    "    \n",
    "#     img = images.view(images.size(0), -1)\n",
    "#     train_dis(images.to(torch.device(\"cuda\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you know actually, training on the gpu is soooo much faster, like a big difference rather than training on the cpu.\n",
    "for xb, _ in train_dl:\n",
    "    x = xb.view(xb.size(0), -1).to(torch.device(\"cuda\"))\n",
    "    print(xb.size(0))\n",
    "    print(D(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images,_ in train_dl:\n",
    "        train_dis(images.to(torch.device('cuda')))\n",
    "        train_gen()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb, _ in train_dl:\n",
    "    xb = xb.view(xb.size(0), -1)\n",
    "    print(D(xb.to(torch.device('cuda'))))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_inp_vector = torch.randn(1,64).to(torch.device('cuda'))\n",
    "print(rand_inp_vector)\n",
    "\n",
    "sh = (G(rand_inp_vector.to(torch.device(\"cuda\"))))\n",
    "\n",
    "sh = sh.cpu().detach()\n",
    "\n",
    "sh = sh.reshape(-1, 250, 250)\n",
    "\n",
    "sh = sh.permute(1,2,0)\n",
    "\n",
    "plt.imshow(sh)\n",
    "\n",
    "\n",
    "print(sh.shape)\n",
    "# gg = tst_out.reshape(-1, 250, 250)\n",
    "# gg = gg.reshape(2,3,250, 250)\n",
    "# gg = gg[0].permute(1,2,0).cpu().detach()\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(gg)\n",
    "\n",
    "img = (img_fld[0][0]).permute(1,2,0)\n",
    "\n",
    "# plt.imshow(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
